---
title: "User Satisfaction Index v1"
author: "Rebecca Weiss"
date: "January 26, 2016"
output: html_document
---

```{r echo=FALSE, results='hide', warning=FALSE, message=FALSE}
source('v1.R') # recoding and another data reshaping
```

# Restrictions

1. Filtered on release users


# Responses by day of the week

```{r, echo=TRUE, fig.align='center'}
#
#data = dplyr::filter(data, updatechannel == 'release') #fail, hadley
data = data[data$updatechannel == 'release',]
submissions = data.frame(table(lubridate::floor_date(data$date, unit="day")))
names(submissions) = c('date', 'count')
submissions$count = as.numeric(submissions$count)
submissions$date = lubridate::ymd(submissions$date)
submissions$wday = lubridate::wday(submissions$date, label=T)
ggplot(submissions, aes(x=wday, y=count, label=count)) + geom_bar(stat="identity") + geom_text(vjust=-1) +theme_pander()
```

# Densities of responses to each question

```{r, echo=TRUE, fig.align='center', fig.height=8}
questions = subset(data, select=c("score","paranoia", "retrospective", "prospective", "control", "expectations1", "expectations2", "expectations3"))
melted_questions = melt(questions)
ggplot(melted_questions, aes(x=value, fill=variable)) + geom_density() + scale_x_continuous(limits=c(-2, 2)) + facet_wrap(~variable, ncol=1) + theme_bw()
```

# Distribution of responses to each question

```{r, echo=TRUE, fig.align='center', fig.height=12}
melted_question_xscore = melt(questions, id.vars = "score")
ggplot(melted_question_xscore, aes(x=as.factor(score), y=value)) + geom_boxplot() + facet_wrap(~variable, ncol=1) + geom_jitter(width=0.5,height=0.5, alpha=0.25) + theme_bw()
```

# Correlations of questions and heartbeat score

```{r, echo=TRUE, fig.align='center'}
summary(questions)
cormat = round(cor(questions, use="pairwise.complete.obs", method="pearson"), 2)
# Taken from here: https://briatte.github.io/ggcorr/
GGally::ggcorr(cormat, geom = "blank", label = TRUE, hjust = 0.75) +
  geom_point(size = 10, aes(color = coefficient > 0, alpha = abs(coefficient) > 0.5)) +
  scale_alpha_manual(values = c("TRUE" = 0.25, "FALSE" = 0)) +
  guides(color = FALSE, alpha = FALSE)
```

# Modeling: Ordered Logistic Regression

```{r}
small_questions = subset(questions, select=c("score", "paranoia", "retrospective", "prospective", "control", "expectations1"))
small_questions = small_questions[complete.cases(small_questions),]
scaled_small_questions = as.data.frame(scale(small_questions[,2:6]))
scaled_small_questions$score = small_questions$score
model = MASS::polr(as.factor(score) ~ paranoia + prospective + control + retrospective + expectations1, data=scaled_small_questions, Hess=TRUE)
phat = as.data.frame(predict(model, type="class"))
pander(table(phat$`predict(model, type = "class")`, small_questions$score))
accuracy = sum(phat$`predict(model, type = "class")` == small_questions$score)/length(small_questions$score)
print(accuracy)
```

```{r}
pander(summary(model))
MASS::stepAIC(model)

model2 = MASS::polr(as.factor(score) ~ prospective + expectations1, data=scaled_small_questions, Hess=TRUE)
phat = as.data.frame(predict(model2, type="class"))
pander(table(phat$`predict(model2, type = "class")`, small_questions$score))
accuracy = sum(phat$`predict(model2, type = "class")` == small_questions$score)/length(small_questions$score)
print(accuracy)
```

# Appendix 

```{r}
summary(data)
sessionInfo()
```